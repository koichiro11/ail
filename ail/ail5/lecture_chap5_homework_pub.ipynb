{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 第5回講義 宿題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 課題. Tensorflowを用いて, MNISTを多層パーセプトロン(MLP)で学習せよ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 注意"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- homework関数を完成させて提出してください\n",
    "    - 訓練データはtrain_X, train_y, テストデータはtest_Xで与えられます\n",
    "    - train_Xとtrain_yをtrain_X, train_yとvalid_X, valid_yに分けるなどしてモデルを学習させてください\n",
    "    - test_Xに対して予想ラベルpred_yを作り, homework関数の戻り値としてください\n",
    "- pred_yのtest_yに対する精度(F値)で評価します\n",
    "- 全体の実行時間がiLect上で60分を超えないようにしてください\n",
    "- homework関数の外には何も書かないでください (必要なものは全てhomework関数に入れてください)\n",
    "- 解答提出時には Answer Cell の内容のみを提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- CNNは使わないでください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**`tf` の以下のモジュールはこの回では使用できないように制限されています. 注意してください.**\n",
    "```python\n",
    "tf.app\n",
    "tf.compat\n",
    "tf.contrib\n",
    "tf.erros\n",
    "tf.gfile\n",
    "tf.graph_util\n",
    "tf.image\n",
    "tf.layers\n",
    "tf.logging\n",
    "tf.losses\n",
    "tf.metrics\n",
    "tf.python_io\n",
    "tf.resource_loader\n",
    "tf.saved_model\n",
    "tf.sdca\n",
    "tf.sets\n",
    "tf.summary\n",
    "tf.sysconfig\n",
    "tf.test\n",
    "tf.train\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "次のセルのhomework関数を完成させて提出してください"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Answer Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def homework(train_X, train_y, test_X):\n",
    "    \n",
    "    import numpy as np\n",
    "    import tensorflow as tf \n",
    "    from sklearn.utils import shuffle\n",
    "    from sklearn.metrics import f1_score\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    # hyperparameter\n",
    "    rng = np.random.RandomState(1234)\n",
    "    random_state = 42\n",
    "    \n",
    "    # method\n",
    "    def one_to_hot(x):\n",
    "        \"\"\"one to hot method\"\"\"\n",
    "        columns = np.unique(x)\n",
    "        X = np.zeros([x.shape[0], len(columns)])\n",
    "        for i, column in enumerate(columns):\n",
    "            X[np.where(x==column), i] = 1\n",
    "        return X\n",
    "    \n",
    "\n",
    "    def get_init_weight(n_in, n_out, weight=0.08):\n",
    "        return rng.uniform(low=-weight, high=weight, size=(n_in, n_out)).astype('float32')\n",
    "    \n",
    "    # class\n",
    "    class EarlyStopping(object):\n",
    "        \"\"\"early stopping\"\"\"\n",
    "        \n",
    "        def __init__(self):\n",
    "            self.stop_count = 0\n",
    "            self.limit = 5\n",
    "            self.best_validation_loss = float('inf')\n",
    "            \n",
    "        def check(self, loss):\n",
    "            if loss < self.best_validation_loss:\n",
    "                self.best_validation_loss = loss\n",
    "                self.stop_count = 0\n",
    "            else:\n",
    "                self.stop_count += 1\n",
    "            \n",
    "            if self.stop_count > self.limit:\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "            \n",
    "    class Model(object):\n",
    "        \"\"\"Multi Perceptron Model\"\"\"\n",
    "\n",
    "        def __init__(self, n_hiddens=[512, 256, 128], act_function=[tf.tanh, tf.tanh, tf.tanh], lr=0.01, ):\n",
    "            tf.reset_default_graph()\n",
    "            self.lr = lr\n",
    "            self.act_functions = act_function\n",
    "            self.act_functions.append(tf.nn.softmax)\n",
    "            self.n_hiddens = n_hiddens\n",
    "\n",
    "        def __call__(self, input_dim, output_dim):\n",
    "            \"\"\"make graph\"\"\"\n",
    "            self.input_dim = input_dim\n",
    "            self.output_dim = output_dim\n",
    "            self.ins = np.concatenate([[self.input_dim], self.n_hiddens])\n",
    "            self.outs = np.concatenate([self.n_hiddens, [self.output_dim]])\n",
    "\n",
    "            # placeholder\n",
    "            self.x = tf.placeholder(tf.float32, [None, self.input_dim], name=\"x\")\n",
    "            self.t = tf.placeholder(tf.float32, [None, self.output_dim], name=\"t\")\n",
    "            self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "            # foward\n",
    "            params = []\n",
    "            u = self.x\n",
    "            for idx, (n_in, n_out) in enumerate(zip(self.ins, self.outs)):\n",
    "                W = tf.Variable(get_init_weight(n_in=n_in, n_out=n_out, weight=0.08), name=\"W%d\" % (idx+1,))\n",
    "                b = tf.Variable(np.zeros(n_out).astype('float32'), name=\"b%d\" % (idx+1,))\n",
    "                params += [W, b]\n",
    "                # dropout\n",
    "                if idx > 0:\n",
    "                    u = tf.nn.dropout(u, self.keep_prob)\n",
    "                u = tf.matmul(u, W) + b\n",
    "                u = self.act_functions[idx](u)\n",
    "            y = u\n",
    "            clipped_y = tf.clip_by_value(y, 1e-10, 1.0)\n",
    "            self.cost = -tf.reduce_mean(tf.reduce_sum(self.t*tf.log(clipped_y), axis=1))\n",
    "\n",
    "            # update\n",
    "            grad_params = tf.gradients(self.cost, params)\n",
    "            updates = [param.assign_sub(self.lr*grad_param) for param, grad_param in zip(params, grad_params)]\n",
    "\n",
    "            # training\n",
    "            self.train = tf.group(*updates)\n",
    "            self.valid = tf.argmax(y, axis=1)\n",
    "\n",
    "        def batch_training(self, batch_train_X, batch_train_y, batch_size = 20):\n",
    "            for start in range(0, batch_train_X.shape[0], batch_size):\n",
    "                batch_X, batch_y = batch_train_X[start:start+batch_size], batch_train_y[start:start+batch_size]\n",
    "                sess.run(self.train, feed_dict={self.x: batch_X, self.t: batch_y, self.keep_prob: 0.8})\n",
    "                    \n",
    "    # main \n",
    "    model = Model()\n",
    "    model(784, 10)\n",
    "\n",
    "    train_y = one_to_hot(train_y)\n",
    "    max_epoch = 1000\n",
    "    early_stopping = EarlyStopping()\n",
    "\n",
    "    train_X, train_y = shuffle(train_X, train_y)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(max_epoch):\n",
    "            train_costs, valid_costs = [], []\n",
    "            batch_train_X, batch_valid_X, batch_train_y, batch_valid_y = train_test_split(train_X, train_y, train_size=0.8, random_state=random_state)\n",
    "            # train\n",
    "            model.batch_training(batch_train_X, batch_train_y)\n",
    "            loss = sess.run(model.cost, feed_dict={model.x: batch_valid_X, model.t: batch_valid_y, model.keep_prob: 1.0})\n",
    "            if early_stopping.check(loss):\n",
    "                break\n",
    "            \n",
    "            if epoch % 5 == 0:\n",
    "                print(loss)\n",
    "\n",
    "        # predict\n",
    "        pred_y = sess.run(model.valid, feed_dict={model.x: test_X, model.keep_prob:1.0})\n",
    "\n",
    "    return pred_y\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "- 以下のvalidate_homework関数を用いてエラーが起きないか動作確認をして下さい。\n",
    "- 提出に際して、以下のscore_homework関数で60分で実行が終わることを確認して下さい。\n",
    "- 評価は以下のscore_homework関数で行われますが、random_stateの値は変更されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checker Cell (for student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "del [\n",
    "    tf.app,\n",
    "    tf.compat,\n",
    "    tf.contrib,\n",
    "    tf.errors,\n",
    "    tf.gfile,\n",
    "    tf.graph_util,\n",
    "    tf.image,\n",
    "    tf.layers,\n",
    "    tf.logging,\n",
    "    tf.losses,\n",
    "    tf.metrics,\n",
    "    tf.python_io,\n",
    "    tf.resource_loader,\n",
    "    tf.saved_model,\n",
    "    tf.sdca,\n",
    "    tf.sets,\n",
    "    tf.summary,\n",
    "    tf.sysconfig,\n",
    "    tf.test,\n",
    "    tf.train\n",
    "]\n",
    "\n",
    "def load_mnist():\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "    mnist_X, mnist_y = shuffle(mnist.data.astype('float32'),\n",
    "                               mnist.target.astype('int32'), random_state=42)\n",
    "\n",
    "    mnist_X = mnist_X / 255.0\n",
    "\n",
    "    return train_test_split(mnist_X, mnist_y,\n",
    "                test_size=0.2,\n",
    "                random_state=42)\n",
    "\n",
    "def validate_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "\n",
    "    # validate for small dataset\n",
    "    train_X_mini = train_X[:100]\n",
    "    train_y_mini = train_y[:100]\n",
    "    test_X_mini = test_X[:100]\n",
    "    test_y_mini = test_y[:100]\n",
    "\n",
    "    pred_y = homework(train_X_mini, train_y_mini, test_X_mini)\n",
    "    print(f1_score(test_y_mini, pred_y, average='macro'))\n",
    "\n",
    "def score_homework():\n",
    "    train_X, test_X, train_y, test_y = load_mnist()\n",
    "    pred_y = homework(train_X, train_y, test_X)\n",
    "    print(f1_score(test_y, pred_y, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.24655\n",
      "2.19885\n",
      "2.14938\n",
      "2.09519\n",
      "2.03316\n",
      "1.95965\n",
      "1.8746\n",
      "1.78793\n",
      "1.70269\n",
      "1.61605\n",
      "1.53354\n",
      "1.45949\n",
      "1.38911\n",
      "1.32048\n",
      "1.25951\n",
      "1.20265\n",
      "1.15149\n",
      "1.10355\n",
      "1.06043\n",
      "1.02541\n",
      "0.990552\n",
      "0.961068\n",
      "0.928016\n",
      "0.905442\n",
      "0.883499\n",
      "0.861016\n",
      "0.847414\n",
      "0.831106\n",
      "0.811653\n",
      "0.799757\n",
      "0.788836\n",
      "0.775997\n",
      "0.766708\n",
      "0.758625\n",
      "0.747289\n",
      "0.739228\n",
      "0.73094\n",
      "0.722213\n",
      "0.715132\n",
      "0.711825\n",
      "0.704838\n",
      "0.700479\n",
      "0.697795\n",
      "0.692762\n",
      "0.692271\n",
      "0.690559\n",
      "0.686226\n",
      "0.680288\n",
      "0.680615\n",
      "0.673555\n",
      "0.671507\n",
      "0.670357\n",
      "0.667416\n",
      "0.664803\n",
      "0.663956\n",
      "0.661393\n",
      "0.657886\n",
      "0.656574\n",
      "0.657193\n",
      "0.651189121698\n"
     ]
    }
   ],
   "source": [
    "validate_homework()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.343226\n",
      "0.199369\n",
      "0.15041\n",
      "0.128352\n",
      "0.112705\n",
      "0.102154\n",
      "0.095442\n",
      "0.0908121\n",
      "0.0874835\n",
      "0.085647\n",
      "0.0820033\n",
      "0.0816428\n",
      "0.0796613\n",
      "0.0791149\n",
      "0.0795057\n",
      "0.978993508345\n",
      "791.7237060070038\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "score_homework()\n",
    "end = time.time() - start\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
