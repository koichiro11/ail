{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Caltech-101 with fixed pre-trained features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Preparing Caltech-101"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Download Caltech-101 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir -p ./Caltech101  # dataset dir\n",
    "axel -n 5 http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz  -o ./Caltech101/101_ObjectCategories.tar.gz\n",
    "tar xzf ./Caltech101/101_ObjectCategories.tar.gz  -C ./Caltech101/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Scan the dataset and setup training and testing splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "\n",
    "# fix the seed to have same training and testing samples\n",
    "random.seed(20) \n",
    "\n",
    "# 30 training samples per class and at most 20 testing samples per class\n",
    "training_sample=30\n",
    "\n",
    "dataset_dir = '{}/Caltech101/101_ObjectCategories'.format(os.getcwd())\n",
    "labels = os.listdir(dataset_dir)\n",
    "train_x, train_y, test_x, test_y = [], [], [], []\n",
    "\n",
    "total = 0\n",
    "for c, category in enumerate(labels):\n",
    "    files = os.listdir('{}/{}'.format(dataset_dir, category))\n",
    "    total += len(files)\n",
    "    random.shuffle(files)\n",
    "    for img in files[:training_sample]:\n",
    "        train_x.append('{}/{}/{}'.format(dataset_dir, category, img))\n",
    "    train_y += [c for _ in range(len(files[:training_sample]))]\n",
    "    for img in files[training_sample: training_sample + 20]: \n",
    "        test_x.append('{}/{}/{}'.format(dataset_dir, category, img))\n",
    "    test_y += [c for _ in range(len(files[training_sample: training_sample + 20]))]\n",
    "\n",
    "print('Total images: {}'.format(total))\n",
    "print('Train images: {}: {}'.format(len(train_x), len(train_y)))\n",
    "print('Validation images: {}: {}'.format(len(test_x), len(test_y)))\n",
    "\n",
    "# random.shuffle(train_list) # Be sure to shuffle training images (otherwise fine-tuning will fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Setup pre-trained network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Just the same as in the previous exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "from scipy.misc import imresize\n",
    "\n",
    "\n",
    "# aspect ratio is kept after resizing\n",
    "def resize_image(img, minimum_length=256):\n",
    "        y, x = img.shape[:2]\n",
    "        # keep aspect ratio\n",
    "        if y <= x:\n",
    "            scale = float(minimum_length) / y\n",
    "            sizes = (minimum_length, int(scale * x))\n",
    "        else:\n",
    "            scale = float(minimum_length) / x\n",
    "            sizes = (int(scale * y), minimum_length)\n",
    "        # If grey picture\n",
    "        if img.ndim == 2:\n",
    "            img = np.tile(img[:, :, np.newaxis], (1, 1, 3))\n",
    "        return imresize(img, sizes, interp='bilinear', mode='RGB')\n",
    "\n",
    "def crop_center(img, sizes=(224, 224)):\n",
    "        y, x, channel = img.shape\n",
    "        center_y, center_x = int(y / 2), int(x / 2)\n",
    "        frame_y, frame_x = sizes\n",
    "        up, down = -int((frame_y + 1) / 2), int(frame_y / 2)\n",
    "        left, right = -int((frame_x + 1) / 2), int(frame_x / 2)\n",
    "        start_h, end_h = max(center_y + up, 0), min(center_y + down, y)\n",
    "        start_w, end_w = max(center_x + left, 0), min(center_x + right, x)\n",
    "        return img[start_h:end_h, start_w:end_w]\n",
    "\n",
    "# define ResNet and load weights\n",
    "model = chainer.links.model.vision.resnet.ResNetLayers('/root/userspace/readonly/chapter1/resnet_50.caffemodel',  50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "# Batch size\n",
    "batch = 10\n",
    "\n",
    "# Send to cpu\n",
    "model.to_gpu()\n",
    "\n",
    "# Prepare\n",
    "features = {'train': np.empty((len(train_x), 2048)),'validation': np.empty((len(test_x), 2048))}\n",
    "crits = {'train': train_y,'validation': test_y}\n",
    "imgs = []\n",
    "\n",
    "# Extract features from training dataset\n",
    "for i in tqdm(range(0, len(train_x), batch), desc='Extracting features (train)'):\n",
    "    imgs = []\n",
    "    for path in train_x[i: i + batch]:\n",
    "        imgs.append(crop_center(resize_image(io.imread(path), 256)))\n",
    "    x = np.array(imgs, dtype=np.float32)\n",
    "    with chainer.using_config('train', False):\n",
    "        y = model.extract(x,  layers=['pool5'])\n",
    "    y['pool5'].to_cpu()\n",
    "    features['train'][i:i + y['pool5'].data.shape[0]] = y['pool5'].data\n",
    "\n",
    "# Extract features from validation dataset\n",
    "for i in tqdm(range(0, len(test_x), batch), desc='Extracting features (validation)'):\n",
    "    imgs = []\n",
    "    for path in test_x[i: i + batch]:\n",
    "        imgs.append(crop_center(resize_image(io.imread(path), 256)))\n",
    "    x = np.array(imgs, dtype=np.float32)\n",
    "    with chainer.using_config('train', False):\n",
    "        y = model.extract(x,  layers=['pool5'])\n",
    "    y['pool5'].to_cpu()\n",
    "    features['validation'][i:i + y['pool5'].data.shape[0]] = y['pool5'].data\n",
    "\n",
    "print('Done extracting features!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import svm\n",
    "\n",
    "print('The number of training dataset: {}'.format(features['train'].shape[0]))\n",
    "print('The number of validation dataset: {}'.format(features['validation'].shape[0]))\n",
    "\n",
    "# Train a linear SVM classifier\n",
    "clf = svm.LinearSVC(C=1)\n",
    "clf.fit(features['train'], crits['train'])\n",
    "yPredTrain = clf.predict(features['train'])\n",
    "yPredTest = clf.predict(features['validation'])\n",
    "\n",
    "print('Training score: {}'.format(np.sum(np.equal(yPredTrain, crits['train'])) / features['train'].shape[0]))\n",
    "print('Validation score: {}'.format(np.sum(np.equal(yPredTest, crits['validation'])) / features['validation'].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exercise\n",
    "* Change the layer from which features are extracted and see how it affects the performance.\n",
    "* Change the pre-trained network to the VGG-16 model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
