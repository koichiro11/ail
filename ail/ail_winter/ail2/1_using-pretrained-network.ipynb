{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using pre-trained network with Chainer: classification and visualization\n",
    "\n",
    "We'll classify an image with ResNet 152 pretrained model.\n",
    "We'll compare CPU and GPU modes and then dig into the model to inspect features and the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chainer version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "import chainer, tqdm, os, cv2, random\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from scipy.misc import imresize\n",
    "from matplotlib import pyplot as plt\n",
    "from time import time\n",
    "\n",
    "print('Chainer version: {}'.format(chainer.__version__))\n",
    "\n",
    "# Function for visualization of classification outpus\n",
    "def show_picture_and_probability(img, probability, labels, howmany=5):\n",
    "    plt.rcParams[\"figure.figsize\"] = [6.4, 4.8]\n",
    "    plt.clf()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.subplots_adjust(left=0.1, right=2.5, bottom=0.1, top=0.9)\n",
    "    x = list(range(1, howmany + 1))\n",
    "    y = []\n",
    "    ticks =[]\n",
    "    for i in np.argsort(probability)[::-1][: howmany]:\n",
    "        y.append(probability[i])\n",
    "        ticks.append(' ,'.join(labels[i].split(',')[:3]))\n",
    "    plt.barh(x, y[::-1], align=\"center\") \n",
    "    plt.yticks(x, ticks[::-1]) \n",
    "    plt.show()\n",
    "\n",
    "# Function for visualization of activations\n",
    "def show_activations(img, activations, howmany=5):\n",
    "    plt.rcParams[\"figure.figsize\"] = [100, 100]\n",
    "    plt.clf()\n",
    "    plt.subplot(1,howmany + 1, 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    for i in range(2, howmany + 1 + 1):\n",
    "        plt.subplot(1,howmany + 1, i)\n",
    "        plt.axis('off')\n",
    "        plt.imshow(cv2.resize(activations[i], (224, 224)))\n",
    "    plt.show()\n",
    "\n",
    "# aspect ratio is kept after resizing\n",
    "def resize_image(img, minimum_length=256):\n",
    "        y, x = img.shape[:2]\n",
    "        # keep aspect ratio\n",
    "        if y <= x:\n",
    "            scale = float(minimum_length) / y\n",
    "            sizes = (minimum_length, int(scale * x))\n",
    "        else:\n",
    "            scale = float(minimum_length) / x\n",
    "            sizes = (int(scale * y), minimum_length)\n",
    "        return imresize(img, sizes, interp='bilinear', mode='RGB')\n",
    "\n",
    "# crop pictures at center\n",
    "def crop_center(img, sizes=(224, 224)):\n",
    "        y, x, channel = img.shape\n",
    "        center_y, center_x = int(y / 2), int(x / 2)\n",
    "        frame_y, frame_x = sizes\n",
    "        up, down = -int((frame_y + 1) / 2), int(frame_y / 2)\n",
    "        left, right = -int((frame_x + 1) / 2), int(frame_x / 2)\n",
    "        start_h, end_h = max(center_y + up, 0), min(center_y + down, y)\n",
    "        start_w, end_w = max(center_x + left, 0), min(center_x + right, x)\n",
    "        return img[start_h:end_h, start_w:end_w]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load ImageNet Pretrained ResNet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare label information\n",
    "labels = []\n",
    "with open('/root/userspace/readonly/chapter1/imagenet_labels.txt', 'r') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "                labels.append(line[:-1])\n",
    "                line = f.readline()\n",
    "# define ResNet and load weights\n",
    "model = chainer.links.model.vision.resnet.ResNetLayers('/root/userspace/readonly/chapter1/resnet_152.caffemodel',  152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. CPU classification\n",
    "* Now we're ready to perform classification. Even though we'll only classify one image, we'll set a batch size of 10 to demonstrate batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Batch size\n",
    "batch = 10\n",
    "\n",
    "# Send to cpu\n",
    "model.to_cpu()\n",
    "\n",
    "# Find pictures\n",
    "files = ['/root/userspace/readonly/chapter1/example_pictures/{}'.format(name) for name in os.listdir('/root/userspace/readonly/chapter1/example_pictures')]\n",
    "\n",
    "# Load pictures randomly\n",
    "random.shuffle(files)\n",
    "imgs = []\n",
    "for i in range(batch):\n",
    "    imgs.append(crop_center(resize_image(io.imread(files[np.random.randint(len(files))]), 256)))\n",
    "x = np.array(imgs, dtype=np.float32)\n",
    "\n",
    "# Forward\n",
    "print('start forwarding')\n",
    "start = time()\n",
    "with chainer.using_config('train', False):\n",
    "    y = model.extract(x,  layers=['prob'])\n",
    "end = time()\n",
    "print('    done')\n",
    "print('Total execution time: {} seconds'.format(end - start))\n",
    "print('Execution time per picture: {} seconds'.format((end - start) / batch))\n",
    "\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[0], y['prob'].data[0], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[1], y['prob'].data[1], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[2], y['prob'].data[2], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[3], y['prob'].data[3], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[4], y['prob'].data[4], labels, howmany=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Switching to GPU mode\n",
    "* Let's see how long classification take and compare it to GPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Batch size\n",
    "batch = 10\n",
    "\n",
    "# Send to cpu\n",
    "model.to_gpu()\n",
    "\n",
    "# Find pictures\n",
    "files = ['/root/userspace/readonly/chapter1/example_pictures/{}'.format(name) for name in os.listdir('/root/userspace/readonly/chapter1/example_pictures')]\n",
    "\n",
    "# Load pictures randomly\n",
    "random.shuffle(files)\n",
    "imgs = []\n",
    "for i in range(batch):\n",
    "    imgs.append(crop_center(resize_image(io.imread(files[np.random.randint(len(files))]), 256)))\n",
    "x = np.array(imgs, dtype=np.float32)\n",
    "\n",
    "# Forward\n",
    "print('start forwarding')\n",
    "start = time()\n",
    "with chainer.using_config('train', False):\n",
    "    y = model.extract(x,  layers=['prob'])\n",
    "end = time()\n",
    "\n",
    "print('    done')\n",
    "print('Total execution time: {} seconds'.format(end - start))\n",
    "print('Execution time per picture: {} seconds'.format((end - start) / batch))\n",
    "\n",
    "# send back to cpu\n",
    "y['prob'].to_cpu()\n",
    "model.to_cpu()\n",
    "\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[0], y['prob'].data[0], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[1], y['prob'].data[1], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[2], y['prob'].data[2], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[3], y['prob'].data[3], labels, howmany=5)\n",
    "# Visualize\n",
    "show_picture_and_probability(imgs[4], y['prob'].data[4], labels, howmany=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Examining intermediate output\n",
    "\n",
    "* Neural Networks are not just a black box; let's take a look at some of the parameters and intermediate activations.\n",
    "\n",
    "First we'll see how to read out the structure of the net in terms of activation and parameter shapes.\n",
    "\n",
    "* For each layer, let's look at the activation shapes, which typically have the form `(batch_size, channel_dim, height, width)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch = 1\n",
    "\n",
    "# Send to cpu\n",
    "model.to_gpu()\n",
    "\n",
    "# Find pictures\n",
    "files = ['/root/userspace/readonly/chapter1/example_pictures/{}'.format(name) for name in os.listdir('/root/userspace/readonly/chapter1/example_pictures')]\n",
    "\n",
    "# Load pictures randomly\n",
    "imgs = []\n",
    "for _ in range(batch):\n",
    "    imgs.append(imresize(io.imread(files[np.random.randint(len(files))]), (256, 256) , interp='bilinear', mode='RGB'))\n",
    "\n",
    "# Shape is (1, 3, 224, 224) -> (batch, channel, height, width)\n",
    "x = np.array(imgs, dtype=np.float32)\n",
    "\n",
    "# Forward\n",
    "print('start forwarding')\n",
    "start = time()\n",
    "with chainer.using_config('train', False):\n",
    "    y = model.extract(x,  layers=['conv1', 'pool1', 'res2', 'res3', 'res4', 'res5', 'pool5', 'fc6', 'prob'])\n",
    "end = time()\n",
    "\n",
    "# Send back to cpu\n",
    "[y[key].to_cpu() for key in y]\n",
    "model.to_cpu()\n",
    "\n",
    "print('    done')\n",
    "print('Total execution time: {} seconds'.format(end - start))\n",
    "print('Execution time per picture: {} seconds'.format((end - start) / batch))\n",
    "print('####################################')\n",
    "print(\"Let's see activation maps:\")\n",
    "\n",
    "print('conv1 shape: {}'.format(y['conv1'][0].data.shape))\n",
    "show_activations(imgs[0], y['conv1'][0].data)\n",
    "\n",
    "print('pool1 shape: {}'.format(y['pool1'][0].data.shape))\n",
    "show_activations(imgs[0], y['pool1'][0].data)\n",
    "\n",
    "print('res2 shape: {}'.format(y['res2'][0].data.shape))\n",
    "show_activations(imgs[0], y['res2'][0].data)\n",
    "\n",
    "print('res3 shape: {}'.format(y['res3'][0].data.shape))\n",
    "show_activations(imgs[0], y['res3'][0].data)\n",
    "\n",
    "print('res4 shape: {}'.format(y['res4'][0].data.shape))\n",
    "show_activations(imgs[0], y['res4'][0].data)\n",
    "\n",
    "print('res5 shape: {}'.format(y['res5'][0].data.shape))\n",
    "show_activations(imgs[0], y['res5'][0].data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
